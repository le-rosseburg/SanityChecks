{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SaliencyMapsCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCT_Fz_jAP9U"
      },
      "source": [
        "import torch, torchvision, statistics, random\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "use_MNIST = False # Using CIFAR10 iff set to false\n",
        "use_subset = False # Set this to True for debugging purposes\n",
        "shuffle_labeling = False\n",
        "print(f\"Using {'only a subset' if use_subset else 'entire dataset'} of {'MNIST' if use_MNIST else 'CIFAR10'}\"\n",
        "      f\" {'with' if shuffle_labeling else 'without'} shuffled labeling!\\n\")\n",
        "\n",
        "\n",
        "\"\"\"Creating datasets:\"\"\"\n",
        "transform = transforms.ToTensor()\n",
        "if use_MNIST:\n",
        "    train_dataset = torchvision.datasets.MNIST(root='../data', train=True, download=True, transform=transform)\n",
        "    val_dataset = torchvision.datasets.MNIST(root='../data', train=False, download=True, transform=transform)\n",
        "else:\n",
        "    train_dataset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
        "    val_dataset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)\n",
        "\n",
        "if shuffle_labeling: random.shuffle(train_dataset.targets)\n",
        "classes = train_dataset.classes\n",
        "\n",
        "if use_subset:\n",
        "    train_dataset = torch.utils.data.Subset(train_dataset, torch.arange(0, 100))\n",
        "    val_dataset = torch.utils.data.Subset(val_dataset, torch.arange(0, 100))\n",
        "\n",
        "print(f'classes: {classes}\\nnumber of instances:\\n\\ttrain: {len(train_dataset)}\\n\\tval: {len(val_dataset)}')\n",
        "\n",
        "\n",
        "\"\"\"Creating dataloaders:\"\"\"\n",
        "batch_size = 32\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "\"\"\"Defining the CNN:\"\"\"\n",
        "if use_MNIST:\n",
        "    # MNIST images are grayscale. Therefore just one in channel\n",
        "    IN_CHANNELS = 1\n",
        "    # 192 activity maps and 28x28 img devided by 2 two times, makes 7x7\n",
        "    N_FLATTENED = 192 * 7 * 7 #\n",
        "else:\n",
        "    # CIFAR images are RGB. Therefore three channels\n",
        "    IN_CHANNELS = 3\n",
        "    # 192 activity maps and 32x32 img devided by 2 two times, makes 8x8\n",
        "    N_FLATTENED = 192 * 8 * 8\n",
        "\n",
        "net = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=IN_CHANNELS, out_channels=48, kernel_size=(3, 3), padding=(1, 1)),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(in_channels=48, out_channels=96, kernel_size=(3, 3), padding=(1, 1)),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Conv2d(in_channels=96, out_channels=192, kernel_size=(3, 3), padding=(1, 1)),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(N_FLATTENED, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        ")\n",
        "\n",
        "# test the model on a single batch\n",
        "# image_batch, target_batch = next(iter(train_dl))\n",
        "# print(net(image_batch).shape)\n",
        "\n",
        "\n",
        "\"\"\"Defining loss function and optimizer:\"\"\"\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=1e-2, momentum=0.9)\n",
        "\n",
        "\n",
        "\"\"\"Training:\"\"\"\n",
        "use_gpu = True if torch.cuda.is_available() else False\n",
        "print(f'Using cuda: {use_gpu}')\n",
        "if use_gpu: net = net.cuda()\n",
        "\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "    losses = []\n",
        "    for inputs, targets in train_dl:\n",
        "        if use_gpu:\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.cuda()\n",
        "\n",
        "        optimizer.zero_grad()               # Reset gradients to zero\n",
        "        outputs = net(inputs)               # Forward pass\n",
        "        loss = loss_func(outputs, targets)  # Compute Loss\n",
        "        loss.backward()                     # Compute the gradients\n",
        "        optimizer.step()                    # Update parameter\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Current training loss {statistics.mean(losses)}\")\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n",
        "\"\"\"Validation:\"\"\"\n",
        "with torch.no_grad():\n",
        "    val_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    for inputs, targets in val_dl:\n",
        "        if use_gpu:\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.cuda()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_func(outputs, targets)\n",
        "        val_loss += loss.item()\n",
        "        predicted = outputs.argmax(1)  # select the class with the largest value\n",
        "\n",
        "        total += len(targets)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "print(f'Validation loss: {val_loss / len(val_dl)}')\n",
        "print(f'Accuracy on the validation set: {100 * correct / total}%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plHE9dG0BvJt"
      },
      "source": [
        "!pip install captum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYRoeFYzBmGZ"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from captum.attr import IntegratedGradients, DeepLift, Occlusion\n",
        "from captum.attr import visualization as viz\n",
        "\n",
        "\n",
        "methods = [\"original_image\", \"blended_heat_map\", \"heat_map\"]\n",
        "\n",
        "# returns img and label at given index from the first batch of\n",
        "# given validation dataloader\n",
        "def getData(val_dl, index):\n",
        "    images, labels = next(iter(val_dl))\n",
        "    if torch.cuda.is_available():\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "    imgTensor = images[index]\n",
        "    imgTensor.requires_grad = True\n",
        "\n",
        "    return imgTensor, labels[index]\n",
        "\n",
        "# turns the given tensor input a plottable image by detaching\n",
        "# transposing\n",
        "def tensor2img(tensor):\n",
        "    return np.transpose(tensor.cpu().detach().numpy(), (1, 2, 0))\n",
        "\n",
        "# plots integrated gradients saliency map of given image\n",
        "def integratedGrads(net, imgTensor, label):\n",
        "    ig = IntegratedGradients(net)\n",
        "    attr_ig = ig.attribute(imgTensor.unsqueeze(0), target=label)\n",
        "    attr_ig = tensor2img(attr_ig.squeeze(0))\n",
        "\n",
        "    signs = [\"\",\"all\",\"all\"]\n",
        "    titles = [\"Original Image\", \"Integrated Gradients - Blended Heat Map\", \"Integrated Gradients - Heat Map\"]\n",
        "    viz.visualize_image_attr_multiple(attr_ig, tensor2img(imgTensor), methods=methods, signs=signs, titles=titles,\n",
        "                                      fig_size=(13,5), show_colorbar=True)\n",
        "\n",
        "# plots deep lift saliency map of given image\n",
        "def deepLift(net, imgTensor, label):\n",
        "    dl = DeepLift(net)\n",
        "    attr_dl = dl.attribute(imgTensor.unsqueeze(0), target=label)\n",
        "    attr_dl = tensor2img(attr_dl.squeeze(0))\n",
        "\n",
        "    signs = [\"\",\"all\",\"all\"]\n",
        "    titles = [\"Original Image\", \"DeepLift - Blended Heat Map\", \"DeepLift - Heat Map\"]\n",
        "    viz.visualize_image_attr_multiple(attr_dl, tensor2img(imgTensor), methods=methods, signs=signs, titles=titles,\n",
        "                                      fig_size=(13,5), show_colorbar=True)\n",
        "\n",
        "# plots occlusion saliency map of given image\n",
        "def occlusionMap(net, imgTensor, label):\n",
        "    occlusion = Occlusion(net)\n",
        "    attr_occ = occlusion.attribute(imgTensor.unsqueeze(0), target=label, sliding_window_shapes=(imgTensor.shape[0], 1, 1))\n",
        "    attr_occ = tensor2img(attr_occ.squeeze(0))\n",
        "\n",
        "    signs = [\"\", \"positive\", \"positive\"]\n",
        "    titles = [\"Original Image\", \"Occlusion - Blended Heat Map\", \"Occlusion - Heat Map\"]\n",
        "    viz.visualize_image_attr_multiple(attr_occ, tensor2img(imgTensor), methods=methods, signs=signs, titles=titles,\n",
        "                                      fig_size=(13, 5), show_colorbar=True)\n",
        "\n",
        "\n",
        "\"\"\"Plotting saliency maps:\"\"\"\n",
        "net.eval()\n",
        "imgTensor, label = getData(val_dl, index=3)\n",
        "\n",
        "integratedGrads(net, imgTensor, label)\n",
        "deepLift(net, imgTensor, label)\n",
        "occlusionMap(net, imgTensor, label)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}